{
  "total_results": 10,
  "papers": [
    {
      "id": "2412.04948v1",
      "title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning",
      "authors": [
        "Peng Yu",
        "Cheng Deng",
        "Beiya Dai",
        "Xinbing Wang",
        "Ying Wen"
      ],
      "abstract": "Autoregressive large language models (LLMs) pre-trained by next token\nprediction are inherently proficient in generative tasks. However, their\nperformance on knowledge-driven tasks such as factual knowledge querying\nremains unsatisfactory. Knowledge graphs (KGs), as high-quality structured\nknowledge bases, can provide reliable knowledge for LLMs, potentially\ncompensating for their knowledge deficiencies. Aligning LLMs with explicit,\nstructured knowledge from KGs has been a challenge; previous attempts either\nfailed to effectively align knowledge representations or compromised the\ngenerative capabilities of LLMs, leading to less-than-optimal outcomes. This\npaper proposes \\textbf{KaLM}, a \\textit{Knowledge-aligned Language Modeling}\napproach, which fine-tunes autoregressive LLMs to align with KG knowledge via\nthe joint objective of explicit knowledge alignment and implicit knowledge\nalignment. The explicit knowledge alignment objective aims to directly optimize\nthe knowledge representation of LLMs through dual-view knowledge graph\ncontrastive learning. The implicit knowledge alignment objective focuses on\nincorporating textual patterns of knowledge into LLMs through triple completion\nlanguage modeling. Notably, our method achieves a significant performance boost\nin evaluations of knowledge-driven tasks, specifically embedding-based\nknowledge graph completion and generation-based knowledge graph question\nanswering.",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2024-12-06T11:08:24+00:00",
      "url": "http://arxiv.org/pdf/2412.04948v1",
      "resource_uri": "arxiv://2412.04948v1"
    },
    {
      "id": "2408.12979v1",
      "title": "Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive Question Answering",
      "authors": [
        "Haowei Du",
        "Dongyan Zhao"
      ],
      "abstract": "Recent works have attempted to integrate external knowledge into LLMs to\naddress the limitations and potential factual errors in LLM-generated content.\nHowever, how to retrieve the correct knowledge from the large amount of\nexternal knowledge imposes a challenge. To this end, we empirically observe\nthat LLMs have already encoded rich knowledge in their pretrained parameters\nand utilizing these internal knowledge improves the retrieval of external\nknowledge when applying them to knowledge-intensive tasks. In this paper, we\npropose a new internal and external knowledge interactive refinement paradigm\ndubbed IEKR to utilize internal knowledge in LLM to help retrieve relevant\nknowledge from the external knowledge base, as well as exploit the external\nknowledge to refine the hallucination of generated internal knowledge. By\nsimply adding a prompt like 'Tell me something about' to the LLMs, we try to\nreview related explicit knowledge and insert them with the query into the\nretriever for external retrieval. The external knowledge is utilized to\ncomplement the internal knowledge into input of LLM for answers. We conduct\nexperiments on 3 benchmark datasets in knowledge-intensive question answering\ntask with different LLMs and domains, achieving the new state-of-the-art.\nFurther analysis shows the effectiveness of different modules in our approach.",
      "categories": [
        "cs.CL"
      ],
      "published": "2024-08-23T10:52:57+00:00",
      "url": "http://arxiv.org/pdf/2408.12979v1",
      "resource_uri": "arxiv://2408.12979v1"
    },
    {
      "id": "2402.13048v1",
      "title": "Stable Knowledge Editing in Large Language Models",
      "authors": [
        "Zihao Wei",
        "Liang Pang",
        "Hanxing Ding",
        "Jingcheng Deng",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Efficient knowledge editing of large language models is crucial for replacing\nobsolete information or incorporating specialized knowledge on a large scale.\nHowever, previous methods implicitly assume that knowledge is localized and\nisolated within the model, an assumption that oversimplifies the interconnected\nnature of model knowledge. The premise of localization results in an incomplete\nknowledge editing, whereas an isolated assumption may impair both other\nknowledge and general abilities. It introduces instability to the performance\nof the knowledge editing method. To transcend these assumptions, we introduce\nStableKE, a method adopts a novel perspective based on knowledge augmentation\nrather than knowledge localization. To overcome the expense of human labeling,\nStableKE integrates two automated knowledge augmentation strategies: Semantic\nParaphrase Enhancement strategy, which diversifies knowledge descriptions to\nfacilitate the teaching of new information to the model, and Contextual\nDescription Enrichment strategy, expanding the surrounding knowledge to prevent\nthe forgetting of related information. StableKE surpasses other knowledge\nediting methods, demonstrating stability both edited knowledge and multi-hop\nknowledge, while also preserving unrelated knowledge and general abilities.\nMoreover, StableKE can edit knowledge on ChatGPT.",
      "categories": [
        "cs.CL"
      ],
      "published": "2024-02-20T14:36:23+00:00",
      "url": "http://arxiv.org/pdf/2402.13048v1",
      "resource_uri": "arxiv://2402.13048v1"
    },
    {
      "id": "2004.08798v1",
      "title": "Knowledge-graph based Proactive Dialogue Generation with Improved Meta-Learning",
      "authors": [
        "Hongcai Xu",
        "Junpeng Bao",
        "Junqing Wang"
      ],
      "abstract": "Knowledge graph-based dialogue systems can narrow down knowledge candidates\nfor generating informative and diverse responses with the use of prior\ninformation, e.g., triple attributes or graph paths. However, most current\nknowledge graph (KG) cover incomplete domain-specific knowledge. To overcome\nthis drawback, we propose a knowledge graph based proactive dialogue generation\nmodel (KgDg) with three components, improved model-agnostic meta-learning\nalgorithm (MAML), knowledge selection in knowledge triplets embedding, and\nknowledge aware proactive response generator. For knowledge triplets embedding\nand selection, we formulate it as a problem of sentence embedding to better\ncapture semantic information. Our improved MAML algorithm is capable of\nlearning general features from a limited number of knowledge graphs, which can\nalso quickly adapt to dialogue generation with unseen knowledge triplets.\nExtensive experiments are conducted on a knowledge aware dialogue dataset\n(DuConv). The results show that KgDg adapts both fast and well to knowledge\ngraph-based dialogue generation and outperforms state-of-the-art baseline.",
      "categories": [
        "cs.CL"
      ],
      "published": "2020-04-19T08:41:12+00:00",
      "url": "http://arxiv.org/pdf/2004.08798v1",
      "resource_uri": "arxiv://2004.08798v1"
    },
    {
      "id": "2112.07924v2",
      "title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation",
      "authors": [
        "Yu Li",
        "Baolin Peng",
        "Yelong Shen",
        "Yi Mao",
        "Lars Liden",
        "Zhou Yu",
        "Jianfeng Gao"
      ],
      "abstract": "Knowledge-grounded dialogue systems are challenging to build due to the lack\nof training data and heterogeneous knowledge sources. Existing systems perform\npoorly on unseen topics due to limited topics covered in the training data. In\naddition, heterogeneous knowledge sources make it challenging for systems to\ngeneralize to other tasks because knowledge sources in different knowledge\nrepresentations require different knowledge encoders. To address these\nchallenges, we present PLUG, a language model that homogenizes different\nknowledge sources to a unified knowledge representation for knowledge-grounded\ndialogue generation tasks. PLUG is pre-trained on a dialogue generation task\nconditioned on a unified essential knowledge representation. It can generalize\nto different downstream knowledge-grounded dialogue generation tasks with a few\ntraining examples. The empirical evaluation on two benchmarks shows that our\nmodel generalizes well across different knowledge-grounded tasks. It can\nachieve comparable performance with state-of-the-art methods under a\nfully-supervised setting and significantly outperforms other methods in\nzero-shot and few-shot settings.",
      "categories": [
        "cs.CL"
      ],
      "published": "2021-12-15T07:11:02+00:00",
      "url": "http://arxiv.org/pdf/2112.07924v2",
      "resource_uri": "arxiv://2112.07924v2"
    },
    {
      "id": "2108.13686v1",
      "title": "Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection",
      "authors": [
        "Shilei Liu",
        "Xiaofeng Zhao",
        "Bochao Li",
        "Feiliang Ren"
      ],
      "abstract": "Knowledge-grounded dialogue is a task of generating a fluent and informative\nresponse based on both conversation context and a collection of external\nknowledge, in which knowledge selection plays an important role and attracts\nmore and more research interest. However, most existing models either select\nonly one knowledge or use all knowledge for responses generation. The former\nmay lose valuable information in discarded knowledge, while the latter may\nbring a lot of noise. At the same time, many approaches need to train the\nknowledge selector with knowledge labels that indicate ground-truth knowledge,\nbut these labels are difficult to obtain and require a large number of manual\nannotations. Motivated by these issues, we propose Knoformer, a dialogue\nresponse generation model based on reinforcement learning, which can\nautomatically select one or more related knowledge from the knowledge pool and\ndoes not need knowledge labels during training. Knoformer is evaluated on two\nknowledge-guided conversation datasets, and achieves state-of-the-art\nperformance.",
      "categories": [
        "cs.CL",
        "I.2.7"
      ],
      "published": "2021-08-31T08:53:08+00:00",
      "url": "http://arxiv.org/pdf/2108.13686v1",
      "resource_uri": "arxiv://2108.13686v1"
    },
    {
      "id": "2302.05717v1",
      "title": "Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning",
      "authors": [
        "Jiayu Liu",
        "Zhenya Huang",
        "Chengxiang Zhai",
        "Qi Liu"
      ],
      "abstract": "Mathematical reasoning is one of the crucial abilities of general artificial\nintelligence, which requires machines to master mathematical logic and\nknowledge from solving problems. However, existing approaches are not\ntransparent (thus not interpretable) in terms of what knowledge has been\nlearned and applied in the reasoning process. In this paper, we propose a\ngeneral Learning by Applying (LeAp) framework to enhance existing models\n(backbones) in a principled way by explicit knowledge learning. In LeAp, we\nperform knowledge learning in a novel problem-knowledge-expression paradigm,\nwith a Knowledge Encoder to acquire knowledge from problem data and a Knowledge\nDecoder to apply knowledge for expression reasoning. The learned mathematical\nknowledge, including word-word relations and word-operator relations, forms an\nexplicit knowledge graph, which bridges the knowledge \"learning\" and \"applying\"\norganically. Moreover, for problem solving, we design a semantics-enhanced\nmodule and a reasoning-enhanced module that apply knowledge to improve the\nproblem comprehension and symbol reasoning abilities of any backbone,\nrespectively. We theoretically prove the superiority of LeAp's autonomous\nlearning mechanism. Experiments on three real-world datasets show that LeAp\nimproves all backbones' performances, learns accurate knowledge, and achieves a\nmore interpretable reasoning process.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2023-02-11T15:15:41+00:00",
      "url": "http://arxiv.org/pdf/2302.05717v1",
      "resource_uri": "arxiv://2302.05717v1"
    },
    {
      "id": "2310.00637v1",
      "title": "Knowledge Engineering using Large Language Models",
      "authors": [
        "Bradley P. Allen",
        "Lise Stork",
        "Paul Groth"
      ],
      "abstract": "Knowledge engineering is a discipline that focuses on the creation and\nmaintenance of processes that generate and apply knowledge. Traditionally,\nknowledge engineering approaches have focused on knowledge expressed in formal\nlanguages. The emergence of large language models and their capabilities to\neffectively work with natural language, in its broadest sense, raises questions\nabout the foundations and practice of knowledge engineering. Here, we outline\nthe potential role of LLMs in knowledge engineering, identifying two central\ndirections: 1) creating hybrid neuro-symbolic knowledge systems; and 2)\nenabling knowledge engineering in natural language. Additionally, we formulate\nkey open research questions to tackle these directions.",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2023-10-01T10:26:25+00:00",
      "url": "http://arxiv.org/pdf/2310.00637v1",
      "resource_uri": "arxiv://2310.00637v1"
    },
    {
      "id": "2310.07289v1",
      "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
      "authors": [
        "Liang Chen",
        "Yang Deng",
        "Yatao Bian",
        "Zeyu Qin",
        "Bingzhe Wu",
        "Tat-Seng Chua",
        "Kam-Fai Wong"
      ],
      "abstract": "Large language models (LLMs) outperform information retrieval techniques for\ndownstream knowledge-intensive tasks when being prompted to generate world\nknowledge. However, community concerns abound regarding the factuality and\npotential implications of using this uncensored knowledge. In light of this, we\nintroduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed to\nsystematically and automatically evaluate generated knowledge from six\nimportant perspectives -- Factuality, Relevance, Coherence, Informativeness,\nHelpfulness and Validity. We conduct an extensive empirical analysis of the\ngenerated knowledge from three different types of LLMs on two widely studied\nknowledge-intensive tasks, i.e., open-domain question answering and\nknowledge-grounded dialogue. Surprisingly, our study reveals that the\nfactuality of generated knowledge, even if lower, does not significantly hinder\ndownstream tasks. Instead, the relevance and coherence of the outputs are more\nimportant than small factual mistakes. Further, we show how to use CONNER to\nimprove knowledge-intensive tasks by designing two strategies: Prompt\nEngineering and Knowledge Selection. Our evaluation code and LLM-generated\nknowledge with human annotations will be released to facilitate future\nresearch.",
      "categories": [
        "cs.CL"
      ],
      "published": "2023-10-11T08:22:37+00:00",
      "url": "http://arxiv.org/pdf/2310.07289v1",
      "resource_uri": "arxiv://2310.07289v1"
    },
    {
      "id": "2310.09725v3",
      "title": "KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models",
      "authors": [
        "Yuyang Bai",
        "Shangbin Feng",
        "Vidhisha Balachandran",
        "Zhaoxuan Tan",
        "Shiqi Lou",
        "Tianxing He",
        "Yulia Tsvetkov"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable performance on\nknowledge-intensive tasks, suggesting that real-world knowledge is encoded in\ntheir model parameters. However, besides explorations on a few probing tasks in\nlimited knowledge domains, it is not well understood how to evaluate LLMs'\nknowledge systematically and how well their knowledge abilities generalize,\nacross a spectrum of knowledge domains and progressively complex task formats.\nTo this end, we propose KGQuiz, a knowledge-intensive benchmark to\ncomprehensively investigate the knowledge generalization abilities of LLMs.\nKGQuiz is a scalable framework constructed from triplet-based knowledge, which\ncovers three knowledge domains and consists of five tasks with increasing\ncomplexity: true-or-false, multiple-choice QA, blank filling, factual editing,\nand open-ended knowledge generation. To gain a better understanding of LLMs'\nknowledge abilities and their generalization, we evaluate 10 open-source and\nblack-box LLMs on the KGQuiz benchmark across the five knowledge-intensive\ntasks and knowledge domains. Extensive experiments demonstrate that LLMs\nachieve impressive performance in straightforward knowledge QA tasks, while\nsettings and contexts requiring more complex reasoning or employing\ndomain-specific facts still present significant challenges. We envision KGQuiz\nas a testbed to analyze such nuanced variations in performance across domains\nand task formats, and ultimately to understand, evaluate, and improve LLMs'\nknowledge abilities across a wide spectrum of knowledge domains and tasks.",
      "categories": [
        "cs.CL"
      ],
      "published": "2023-10-15T04:00:36+00:00",
      "url": "http://arxiv.org/pdf/2310.09725v3",
      "resource_uri": "arxiv://2310.09725v3"
    }
  ]
}