{
  "total_results": 10,
  "papers": [
    {
      "id": "2007.06813v1",
      "title": "BDTF: A Blockchain-Based Data Trading Framework with Trusted Execution Environment",
      "authors": [
        "Guoxiong Su",
        "Wenyuan Yang",
        "Zhengding Luo",
        "Yinghong Zhang",
        "Zhiqiang Bai",
        "Yuesheng Zhu"
      ],
      "abstract": "The need for data trading promotes the emergence of data market. However, in\nconventional data markets, both data buyers and data sellers have to use a\ncentralized trading platform which might be dishonest. A dishonest centralized\ntrading platform may steal and resell the data seller's data, or may refuse to\nsend data after receiving payment from the data buyer. It seriously affects the\nfair data transaction and harm the interests of both parties to the\ntransaction. To address this issue, we propose a novel blockchain-based data\ntrading framework with Trusted Execution Environment (TEE) to provide a trusted\ndecentralized platform for fair data trading. In our design, a blockchain\nnetwork is proposed to realize the payments from data buyers to data sellers,\nand a trusted exchange is built by using a TEE for the first time to achieve\nfair data transmission. With these help, data buyers and data sellers can\nconduct transactions directly. We implement our proposed framework on Ethereum\nand Intel SGX, security analysis and experimental results have demonstrated\nthat the framework proposed can effectively guarantee the fair completion of\ndata tradings.",
      "categories": [
        "cs.CR"
      ],
      "published": "2020-07-14T04:46:54+00:00",
      "url": "http://arxiv.org/pdf/2007.06813v1",
      "resource_uri": "arxiv://2007.06813v1"
    },
    {
      "id": "2111.09872v1",
      "title": "A big data intelligence marketplace and secure analytics experimentation platform for the aviation industry",
      "authors": [
        "Dimitrios Miltiadou",
        "Stamatis Pitsios",
        "Dimitrios Spyropoulos",
        "Dimitrios Alexandrou",
        "Fenareti Lampathaki",
        "Domenico Messina",
        "Konstantinos Perakis"
      ],
      "abstract": "The unprecedented volume, diversity and richness of aviation data that can be\nacquired, generated, stored, and managed provides unique capabilities for the\naviation-related industries and pertains value that remains to be unlocked with\nthe adoption of the innovative Big Data Analytics technologies. Despite the\nlarge efforts and investments on research and innovation, the Big Data\ntechnologies introduce a number of challenges to its adopters. Besides the\neffective storage and access to the underlying big data, efficient data\nintegration and data interoperability should be considered, while at the same\ntime multiple data sources should be effectively combined by performing data\nexchange and data sharing between the different stakeholders. However, this\nreveals additional challenges for the crucial preservation of the information\nsecurity of the collected data, the trusted and secure data exchange and data\nsharing, as well as the robust data access control. The current paper aims to\nintroduce the ICARUS big data-enabled platform that aims provide a multi-sided\nplatform that offers a novel aviation data and intelligence marketplace\naccompanied by a trusted and secure analytics workspace. It holistically\nhandles the complete big data lifecycle from the data collection, data curation\nand data exploration to the data integration and data analysis of data\noriginating from heterogeneous data sources with different velocity, variety\nand volume in a trusted and secure manner.",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2021-11-18T18:51:40+00:00",
      "url": "http://arxiv.org/pdf/2111.09872v1",
      "resource_uri": "arxiv://2111.09872v1"
    },
    {
      "id": "2005.05079v1",
      "title": "A Survey on Sampling and Profiling over Big Data (Technical Report)",
      "authors": [
        "Zhicheng Liu",
        "Aoqian Zhang"
      ],
      "abstract": "Due to the development of internet technology and computer science, data is\nexploding at an exponential rate. Big data brings us new opportunities and\nchallenges. On the one hand, we can analyze and mine big data to discover\nhidden information and get more potential value. On the other hand, the 5V\ncharacteristic of big data, especially Volume which means large amount of data,\nbrings challenges to storage and processing. For some traditional data mining\nalgorithms, machine learning algorithms and data profiling tasks, it is very\ndifficult to handle such a large amount of data. The large amount of data is\nhighly demanding hardware resources and time consuming. Sampling methods can\neffectively reduce the amount of data and help speed up data processing. Hence,\nsampling technology has been widely studied and used in big data context, e.g.,\nmethods for determining sample size, combining sampling with big data\nprocessing frameworks. Data profiling is the activity that finds metadata of\ndata set and has many use cases, e.g., performing data profiling tasks on\nrelational data, graph data, and time series data for anomaly detection and\ndata repair. However, data profiling is computationally expensive, especially\nfor large data sets. Therefore, this paper focuses on researching sampling and\nprofiling in big data context and investigates the application of sampling in\ndifferent categories of data profiling tasks. From the experimental results of\nthese studies, the results got from the sampled data are close to or even\nexceed the results of the full amount of data. Therefore, sampling technology\nplays an important role in the era of big data, and we also have reason to\nbelieve that sampling technology will become an indispensable step in big data\nprocessing in the future.",
      "categories": [
        "cs.DB"
      ],
      "published": "2020-05-08T02:54:07+00:00",
      "url": "http://arxiv.org/pdf/2005.05079v1",
      "resource_uri": "arxiv://2005.05079v1"
    },
    {
      "id": "2407.00036v1",
      "title": "LiveData -- A Worldwide Data Mesh for Stratified Data",
      "authors": [
        "Simone Bocca",
        "Amarsanaa Ganbold",
        "Tsolmon Zundui"
      ],
      "abstract": "Data reuse is fundamental for reducing the data integration effort required\nto build data supporting new applications, especially in data scarcity\ncontexts. However, data reuse requires to deal with data heterogeneity, which\nis always present in data coming from different sources. Such heterogeneity\nappears at different levels, like the language used by the data, the structure\nof the information it represents, and the data types and formats adopted by the\ndatasets. Despite the valuable insights gained by reusing data across contexts,\ndealing with data heterogeneity is still a high price to pay. Additionally,\ndata reuse is hampered by the lack of data distribution infrastructures\nsupporting the production and distribution of quality and interoperable data.\nThese issues affecting data reuse are amplified considering cross-country data\nreuse, where geographical and cultural differences are more pronounced. In this\npaper, we propose LiveData, a cross-country data distribution network handling\nhigh quality and diversity-aware data. LiveData is composed by different nodes\nhaving an architecture providing components for the generation and distribution\nof a new type of data, where heterogeneity is transformed into information\ndiversity and considered as a feature, explicitly defined and used to satisfy\nthe data users purposes. This paper presents the specification of the LiveData\nnetwork, by defining the architecture and the type of data handled by its\nnodes. This specification is currently being used to implement a concrete use\ncase for data reuse and integration between the University of Trento (Italy)\nand the National University of Mongolia.",
      "categories": [
        "cs.DB",
        "cs.DC"
      ],
      "published": "2024-05-27T09:29:54+00:00",
      "url": "http://arxiv.org/pdf/2407.00036v1",
      "resource_uri": "arxiv://2407.00036v1"
    },
    {
      "id": "1910.06115v1",
      "title": "Microservices based Linked Data Quality Model for Buildings Energy Management Services",
      "authors": [
        "Muhammad Aslam Jarwar",
        "Sajjad Ali",
        "Ilyoung Chong"
      ],
      "abstract": "During the production, distribution, and consumption of energy, a large\nquantity of data is generated. For efficiently using of energy resources other\nsupplementary data such as building information, weather, and environmental\ndata etc. are also collected and used. All these energy data and relevant data\nis published as linked data in order to enhance the reusability of data and\nmaximization of energy management services capability. However, the quality of\nthis linked data is questionable because of wear and tears of sensors,\nunreliable communication channels, and highly diversification of data sources.\nThe provision of high-quality energy management services requires high quality\nlinked data, which reduces billing cost and improve the quality of the living\nenvironment. Assessment and improvement methodologies for the quality of data\nalong with linked data needs to process very diverse data from highly diverse\ndata sources. Microservices based data-driven architecture has great\nsignificance to processes highly diverse linked data with modularity,\nscalability, and reliability. This paper proposed microservices based\narchitecture along with domain data and metadata ontologies to enhance and\nassess energy-related linked data quality.",
      "categories": [
        "cs.CY"
      ],
      "published": "2019-10-11T14:09:03+00:00",
      "url": "http://arxiv.org/pdf/1910.06115v1",
      "resource_uri": "arxiv://1910.06115v1"
    },
    {
      "id": "2506.11010v1",
      "title": "Data Science: a Natural Ecosystem",
      "authors": [
        "Emilio Porcu",
        "Roy El Moukari",
        "Laurent Najman",
        "Francisco Herrera",
        "Horst Simon"
      ],
      "abstract": "This manuscript provides a holistic (data-centric) view of what we term\nessential data science, as a natural ecosystem with challenges and missions\nstemming from the data universe with its multiple combinations of the 5D\ncomplexities (data structure, domain, cardinality, causality, and ethics) with\nthe phases of the data life cycle. Data agents perform tasks driven by specific\ngoals. The data scientist is an abstract entity that comes from the logical\norganization of data agents with their actions. Data scientists face challenges\nthat are defined according to the missions. We define specific\ndiscipline-induced data science, which in turn allows for the definition of\npan-data science, a natural ecosystem that integrates specific disciplines with\nthe essential data science. We semantically split the essential data science\ninto computational, and foundational. We claim that there is a serious threat\nof divergence between computational and foundational data science. Especially,\nif no approach is taken to rate whether a data universe discovery should be\nuseful or not. We suggest that rigorous approaches to measure the usefulness of\ndata universe discoveries might mitigate such a divergence.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "stat.ML"
      ],
      "published": "2025-04-25T08:43:27+00:00",
      "url": "http://arxiv.org/pdf/2506.11010v1",
      "resource_uri": "arxiv://2506.11010v1"
    },
    {
      "id": "2409.18449v2",
      "title": "Towards Personal Data Sharing Autonomy:A Task-driven Data Capsule Sharing System",
      "authors": [
        "Qiuyun Lyu",
        "Yilong Zhou",
        "Yizhi Ren",
        "Zhen Wang",
        "Yunchuan Guo"
      ],
      "abstract": "Personal data custodian services enable data owners to share their data with\ndata consumers in a convenient manner, anytime and anywhere. However, with data\nhosted in these services being beyond the control of the data owners, it raises\nsignificant concerns about privacy in personal data sharing. Many schemes have\nbeen proposed to realize fine-grained access control and privacy protection in\ndata sharing. However, they fail to protect the rights of data owners to their\ndata under the law, since their designs focus on the management of system\nadministrators rather than enhancing the data owners' privacy. In this paper,\nwe introduce a novel task-driven personal data sharing system based on the data\ncapsule paradigm realizing personal data sharing autonomy. It enables data\nowners in our system to fully control their data, and share it autonomously.\nSpecifically, we present a tamper-resistant data capsule encapsulation method,\nwhere the data capsule is the minimal unit for independent and secure personal\ndata storage and sharing. Additionally, to realize selective sharing and\ninformed-consent based authorization, we propose a task-driven data sharing\nmechanism that is resistant to collusion and EDoS attacks. Furthermore, by\nupdating parts of the data capsules, the permissions granted to data consumers\ncan be immediately revoked. Finally, we conduct a security and performance\nanalysis, proving that our scheme is correct, sound, and secure, as well as\nrevealing more advantageous features in practicality, compared with the\nstate-of-the-art schemes.",
      "categories": [
        "cs.CR"
      ],
      "published": "2024-09-27T05:13:33+00:00",
      "url": "http://arxiv.org/pdf/2409.18449v2",
      "resource_uri": "arxiv://2409.18449v2"
    },
    {
      "id": "1809.01699v2",
      "title": "Data Lakes, Clouds and Commons: A Review of Platforms for Analyzing and Sharing Genomic Data",
      "authors": [
        "Robert L. Grossman"
      ],
      "abstract": "Data commons collate data with cloud computing infrastructure and commonly\nused software services, tools and applications to create biomedical resources\nfor the large-scale management, analysis, harmonization, and sharing of\nbiomedical data. Over the past few years, data commons have been used to\nanalyze, harmonize and share large scale genomics datasets. Data ecosystems can\nbe built by interoperating multiple data commons. It can be quite labor\nintensive to curate, import and analyze the data in a data commons. Data lakes\nprovide an alternative to data commons and simply provide access to data, with\nthe data curation and analysis deferred until later and delegated to those that\naccess the data. We review software platforms for managing, analyzing and\nsharing genomic data, with an emphasis on data commons, but also covering data\necosystems and data lakes.",
      "categories": [
        "q-bio.GN",
        "cs.CY"
      ],
      "published": "2018-09-05T19:24:13+00:00",
      "url": "http://arxiv.org/pdf/1809.01699v2",
      "resource_uri": "arxiv://1809.01699v2"
    },
    {
      "id": "2206.03881v1",
      "title": "Towards Schema Inference for Data Lakes",
      "authors": [
        "Nour Alhammad",
        "Alex Bogatu",
        "Norman W Paton"
      ],
      "abstract": "A data lake is a repository of data with potential for future analysis.\nHowever, both discovering what data is in a data lake and exploring related\ndata sets can take significant effort, as a data lake can contain an\nintimidating amount of heterogeneous data. In this paper, we propose the use of\nschema inference to support the interpretation of the data in the data lake. If\na data lake is to support a schema-on-read paradigm, understanding the existing\nschema of relevant portions of the data lake seems like a prerequisite. In this\npaper, we make use of approximate indexes that can be used for data discovery\nto inform the inference of a schema for a data lake, consisting of entity types\nand the relationships between them. The specific approach identifies candidate\nentity types by clustering similar data sets from the data lake, and then\nrelationships between data sets in different clusters are used to inform the\nidentification of relationships between the entity types. The approach is\nevaluated using real-world data repositories, to identify where the proposal is\neffective, and to inform the identification of areas for further work.",
      "categories": [
        "cs.DB"
      ],
      "published": "2022-06-08T13:25:46+00:00",
      "url": "http://arxiv.org/pdf/2206.03881v1",
      "resource_uri": "arxiv://2206.03881v1"
    },
    {
      "id": "2004.02808v1",
      "title": "High-Dimensional Data Set Simplification by Laplace-Beltrami Operator",
      "authors": [
        "Chenkai Xu",
        "Hongwei Lin"
      ],
      "abstract": "With the development of the Internet and other digital technologies, the\nspeed of data generation has become considerably faster than the speed of data\nprocessing. Because big data typically contain massive redundant information,\nit is possible to significantly simplify a big data set while maintaining the\nkey information it contains. In this paper, we develop a big data\nsimplification method based on the eigenvalues and eigenfunctions of the\nLaplace-Beltrami operator (LBO). Specifically, given a data set that can be\nconsidered as an unorganized data point set in high-dimensional space, a\ndiscrete LBO defined on the big data set is constructed and its eigenvalues and\neigenvectors are calculated. Then, the local extremum and the saddle points of\nthe eigenfunctions are proposed to be the feature points of a data set in\nhigh-dimensional space, constituting a simplified data set. Moreover, we\ndevelop feature point detection methods for the functions defined on an\nunorganized data point set in high-dimensional space, and devise metrics for\nmeasuring the fidelity of the simplified data set to the original set. Finally,\nexamples and applications are demonstrated to validate the efficiency and\neffectiveness of the proposed methods, demonstrating that data set\nsimplification is a method for processing a maximum-sized data set using a\nlimited data processing capability.",
      "categories": [
        "cs.CV"
      ],
      "published": "2020-03-23T13:52:58+00:00",
      "url": "http://arxiv.org/pdf/2004.02808v1",
      "resource_uri": "arxiv://2004.02808v1"
    }
  ]
}